from fastapi import FastAPI, File, UploadFile
from fastapi.responses import StreamingResponse

from openai import OpenAI
from dotenv import load_dotenv
import os
import json

# Initialize the OpenAI API client
client = OpenAI(api_key="your_api_key_here")

# Initialize the FastAPI application
app = FastAPI()

# Endpoint to handle POST requests for conversational AI interaction
@app.post("/talk")
async def post_audio(file: UploadFile = File(...)):
    # Transcribe audio file uploaded by the user
    user_message = transcribe_audio(file)
    
    # Get response from OpenAI's chat API based on user's message
    chat_response = get_chat_response(user_message)

    # Convert text response to speech audio file
    audio_file = text_to_speech(chat_response)
    
    # Function to stream the audio file back to the client
    def iterfile():
        with open(audio_file, mode="rb") as file_like:
            yield from file_like

    # Return a StreamingResponse object with the audio file
    return StreamingResponse(iterfile(), media_type="audio/mpeg")


# Function to convert text generated by GPT-3.5 into speech using OpenAI's TTS API
def text_to_speech(gpt_message):
    # Path to save the generated speech file
    speech_file_path = "./response.mp3"
    
    # Generate speech from text using OpenAI's TTS API
    response = client.audio.speech.create(
        model="tts-1",
        voice="alloy",
        input=gpt_message
    )

    # Stream the generated speech to the specified file
    response.stream_to_file(speech_file_path)
    
    return speech_file_path


# Function to transcribe audio file uploaded by the user
def transcribe_audio(file):
    # Save uploaded file locally
    file_location = f"./{file.filename}"
    with open(file_location, "wb+") as file_object:
        file_object.write(file.file.read())

        # Transcribe audio to text using OpenAI's transcription API
        transcription = client.audio.transcriptions.create(
            model="whisper-1", 
            file=file_object, 
            response_format="text"
        )
    
    return transcription


# Function to get chat response from OpenAI based on user's message
def get_chat_response(user_message):
    # Save user's message to the database
    save_user_message(user_message)

    # Load conversation history from the database
    messages = load_messages()

    # Get AI response from OpenAI's chat API
    gpt_response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages
    )

    # Save AI's response to the database
    save_gpt_message(gpt_response.choices[0].message.content)

    # Return AI's response
    return gpt_response.choices[0].message.content


# Function to load messages from the database
def load_messages():
    messages = []
    file = 'database.json'

    # Check if the database file is empty
    empty = os.stat(file).st_size == 0

    # If not empty, load messages from the database
    if not empty:
        with open(file) as db_file:
            data = json.load(db_file)
            for item in data:
                messages.append(item)
    else:
        # If empty, initialize with a system message
        messages.append(
            {"role":"system", "content":"You are an interviewer named Greg. Have an interview with the software engineer candidate."}
        )

    return messages


# Function to save AI's response to the database
def save_gpt_message(gpt_response):
    file = 'database.json'
    messages = load_messages()

    # Append AI's response to the messages list
    messages.append({"role":"assistant", "content": gpt_response})

    # Write messages list back to the database file
    with open(file, "w") as db_file:
        json.dump(messages, db_file)


# Function to save user's message to the database
def save_user_message(user_message):
    file = 'database.json'
    messages = load_messages()

    # Append user's message to the messages list
    messages.append({"role":"user", "content": user_message})

    # Write messages list back to the database file
    with open(file, "w") as db_file:
        json.dump(messages, db_file)